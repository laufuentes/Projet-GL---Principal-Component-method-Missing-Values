{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate synthetic datasets !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer  \n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from src.utils import *\n",
    "from src.algorithms import * \n",
    "from src.metrics_FAMD import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction to compute metrics for the generated datasets\n",
    "def compute_metrics(df, cat_idx, n_it, n_components, proba_non_missing):\n",
    "    \"\"\" Compute metrics for different missing probabilities     \n",
    "    Args: \n",
    "        df (pd.DataFrame): Dataframe to  \n",
    "        proba_non_missing (list of float) : List of probabilities that a value is not missing\n",
    "\n",
    "    Returns:\n",
    "        data_missing_raw (pd.DataFrame): Masked dataframe hence containing missing values \n",
    "\n",
    "    \"\"\"\n",
    "    # Categorical Variables :\n",
    "    idx_k2 = pd.Index(cat_idx)\n",
    "    # Continuous Variables\n",
    "    idx_k1 = df.columns.difference(idx_k2)\n",
    "\n",
    "    dict_dfs = {}\n",
    "    for p in proba_non_missing: \n",
    "        df_missing = create_missingness(df, p)\n",
    "        # Encode dummy variables in the dataframe and in the dataframe with missing values :\n",
    "        df_missing_dummy, idx_j, nb_values_per_cat_df = encode_dummy_variables(df_missing, idx_k2)\n",
    "        df_dummy = encode_dummy_variables(df, idx_k2)[0]\n",
    "        dict_dfs.update({p:[idx_k1, idx_j, df_missing_dummy, df_dummy, nb_values_per_cat_df]})\n",
    "        #print(\"proba non missing: \" f'{p}', \"missingness rate: \",df_missing.isna().sum().sum()/(df_missing.shape[0]*df_missing.shape[1]))\n",
    "\n",
    "    #IFAMD\n",
    "    fc_rate = []\n",
    "    nmrse = []\n",
    "\n",
    "    for p,values in dict_dfs.items(): \n",
    "        k1, k_j, df_missing, df_true, nb_val_per_car = values\n",
    "        C0_missing, Categ_missing = df_missing.isna()[k1].to_numpy(), df_missing.isna()[k_j].to_numpy()  \n",
    "        \n",
    "        #Computation of iterative FAMD\n",
    "        ifamd_df = IterativeFAMDImputer(n_components=n_components, data=df_missing, k1=k1, k2=k_j, nb_values_per_cat = nb_val_per_car)\n",
    "        ifamd_df.impute(n_it)\n",
    "        df = ifamd_df.df\n",
    "\n",
    "\n",
    "        # We encode categories into 0,1\n",
    "        res = ifamd_df.df[ifamd_df.k2].copy()\n",
    "        pos = 0\n",
    "        for h in range (len(idx_k2)) :\n",
    "            col = [idx_j[pos+i] for i in range (nb_values_per_cat_df[h])]\n",
    "            res[\"max_value\"] = ifamd_df.df[col].max(axis = 1)\n",
    "            for value in col:\n",
    "                res[value] = (res[value] == res[\"max_value\"]).astype(int)\n",
    "            pos += nb_values_per_cat_df[h]\n",
    "        res = res[ifamd_df.k2] \n",
    "\n",
    "        #Compute metrics \n",
    "        fc_rate.append(metric_fc(res[Categ_missing], df_true[k_j][Categ_missing]))\n",
    "\n",
    "        # For continuous variables: \n",
    "        nmrse.append(compute_nrmse_weighted(df[k1][C0_missing].astype(int), df_true[k1][C0_missing]))\n",
    "\n",
    "    fc_rate = np.array(fc_rate)\n",
    "    nmrse = np.array(nmrse)\n",
    "\n",
    "    return fc_rate, nmrse, idx_j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed to create reproductible results\n",
    "np.random.seed(21032024)\n",
    "\n",
    "# Sample size :\n",
    "n = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters of the first dataset created in the paper : (3.1 Relationships between continuous and categorical variables)\n",
    "\n",
    "S = 2   \n",
    "K = [1,3]  #K[s] = number of times the variable s (s in {1,...,S}) is duplicated in the dataset\n",
    "cat = 2 #number of categorical variables\n",
    "cat_idx = [1,2] #index of the categorical variables\n",
    "nb_of_cat_per_var = [4,4] #number of categories for each categorical variable\n",
    "\n",
    "df_3_1_snr1 = create_dataset(n, S, K, cat, cat_idx, nb_of_cat_per_var, 1)\n",
    "df_3_1_snr3 = create_dataset(n, S, K, cat, cat_idx, nb_of_cat_per_var, 3)\n",
    "#df_3_1_snr1.to_csv(\"datasets/df_3_1_snr1.csv\", index=False, quoting=csv.QUOTE_NONNUMERIC)\n",
    "#df_3_1_snr3.to_csv(\"datasets/df_3_1_snr3.csv\", index=False, quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define number of iterations \n",
    "n_it = 1000\n",
    "n_components = 8\n",
    "\n",
    "# Inject missing values into the dataframe :\n",
    "proba_non_missing = [0.7, 0.8, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_simulations = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged in 22\n",
      "Converged in 10\n",
      "Converged in 5\n",
      "Converged in 9\n",
      "Converged in 9\n",
      "Converged in 6\n",
      "Converged in 12\n",
      "Converged in 9\n",
      "Converged in 5\n",
      "Converged in 18\n",
      "Converged in 14\n",
      "Converged in 4\n",
      "Converged in 16\n",
      "Converged in 8\n",
      "Converged in 4\n",
      "Converged in 14\n",
      "Converged in 15\n",
      "Converged in 5\n",
      "Converged in 14\n",
      "Converged in 8\n",
      "Converged in 6\n",
      "Converged in 13\n",
      "Converged in 9\n",
      "Converged in 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adjev\\kDrive\\M2\\Periode3\\GL\\GL_GIT\\Projet-GL---Principal-Component-method-Missing-Values\\src\\metrics_FAMD.py:43: RuntimeWarning: invalid value encountered in sqrt\n",
      "  nrmse = np.sqrt(nrmse_numerator / nrmse_denominator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged in 10\n",
      "Converged in 9\n",
      "Converged in 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adjev\\kDrive\\M2\\Periode3\\GL\\GL_GIT\\Projet-GL---Principal-Component-method-Missing-Values\\src\\metrics_FAMD.py:43: RuntimeWarning: invalid value encountered in sqrt\n",
      "  nrmse = np.sqrt(nrmse_numerator / nrmse_denominator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged in 10\n",
      "Converged in 10\n",
      "Converged in 5\n",
      "Converged in 14\n",
      "Converged in 8\n",
      "Converged in 5\n",
      "Converged in 13\n",
      "Converged in 10\n",
      "Converged in 6\n",
      "Converged in 14\n",
      "Converged in 9\n",
      "Converged in 7\n",
      "Converged in 17\n",
      "Converged in 8\n",
      "Converged in 5\n",
      "Converged in 14\n",
      "Converged in 8\n",
      "Converged in 6\n",
      "Converged in 14\n",
      "Converged in 15\n",
      "Converged in 6\n",
      "Converged in 11\n",
      "Converged in 7\n",
      "Converged in 5\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [82]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n_sim \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_simulations):\n\u001b[0;32m     11\u001b[0m     df_3_1_snr3 \u001b[38;5;241m=\u001b[39m create_dataset(n, S, K, cat, cat_idx, nb_of_cat_per_var, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m     fc_rate, nmrse, idx_j \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_3_1_snr3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcat_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_it\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_components\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproba_non_missing\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     mean_fc_rate \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mmean(fc_rate[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(proba_non_missing))]\n\u001b[0;32m     14\u001b[0m     rnmse_list_3_1_snr3\u001b[38;5;241m.\u001b[39mappend(nmrse)\n",
      "Input \u001b[1;32mIn [78]\u001b[0m, in \u001b[0;36mcompute_metrics\u001b[1;34m(df, cat_idx, n_it, n_components, proba_non_missing)\u001b[0m\n\u001b[0;32m     49\u001b[0m res \u001b[38;5;241m=\u001b[39m res[ifamd_df\u001b[38;5;241m.\u001b[39mk2] \n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m#Compute metrics \u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m fc_rate\u001b[38;5;241m.\u001b[39mappend(\u001b[43mmetric_fc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m[\u001b[49m\u001b[43mCateg_missing\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_true\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk_j\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mCateg_missing\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# For continuous variables: \u001b[39;00m\n\u001b[0;32m     55\u001b[0m nmrse\u001b[38;5;241m.\u001b[39mappend(compute_nrmse_weighted(df[k1][C0_missing]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m), df_true[k1][C0_missing]))\n",
      "File \u001b[1;32mc:\\Users\\adjev\\kDrive\\M2\\Periode3\\GL\\GL_GIT\\Projet-GL---Principal-Component-method-Missing-Values\\src\\metrics_FAMD.py:18\u001b[0m, in \u001b[0;36mmetric_fc\u001b[1;34m(df_categ, true_df_categ)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(df_categ\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mto_numpy()): \n\u001b[0;32m     17\u001b[0m     cm \u001b[38;5;241m=\u001b[39m confusion_matrix(true_df_categ[col], df_categ[col])\n\u001b[1;32m---> 18\u001b[0m     fc[i] \u001b[38;5;241m=\u001b[39m(\u001b[43mcm\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m cm[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m cm\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fc\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "S = 2   \n",
    "K = [1,3]  #K[s] = number of times the variable s (s in {1,...,S}) is duplicated in the dataset\n",
    "cat = 2 #number of categorical variables\n",
    "cat_idx = [1,2] #index of the categorical variables\n",
    "nb_of_cat_per_var = [4,4] #number of categories for each categorical variable\n",
    "\n",
    "mean_fc_rate_list_3_1_snr3 = []\n",
    "rnmse_list_3_1_snr3 = []\n",
    "\n",
    "for n_sim in range(n_simulations):\n",
    "    df_3_1_snr3 = create_dataset(n, S, K, cat, cat_idx, nb_of_cat_per_var, 3)\n",
    "    fc_rate, nmrse, idx_j = compute_metrics(df_3_1_snr3, pd.Index(cat_idx).map(str), n_it, n_components, proba_non_missing)\n",
    "    mean_fc_rate = [np.mean(fc_rate[i]) for i in range(len(proba_non_missing))]\n",
    "    rnmse_list_3_1_snr3.append(nmrse)\n",
    "    mean_fc_rate_list_3_1_snr3.append(mean_fc_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.24107142857142858, 0.24285714285714285, 0.25],\n",
       " [0.2798507462686567, 0.20652173913043478, 0.20833333333333334],\n",
       " [0.225, 0.21621621621621623, 0.25],\n",
       " [0.23828125, 0.23369565217391303, 0.14423076923076922],\n",
       " [0.24206349206349206, 0.24999999999999997, 0.23076923076923078],\n",
       " [0.21428571428571427, 0.20833333333333331, 0.2],\n",
       " [0.21929824561403508, 0.2421875, 0.22222222222222224],\n",
       " [0.2543103448275862, 0.2361111111111111, 0.16999999999999998],\n",
       " [0.2379032258064516, 0.19444444444444445, 0.19117647058823528],\n",
       " [0.26492537313432835, 0.195, 0.21875],\n",
       " [0.2246376811594203, 0.21794871794871792, 0.25],\n",
       " [0.28787878787878785, 0.2717391304347826, 0.19047619047619047],\n",
       " [0.25462962962962965, 0.20714285714285713, 0.17857142857142855],\n",
       " [0.25396825396825395, 0.2134146341463415, 0.18055555555555552],\n",
       " [0.26102941176470584, 0.20833333333333331, 0.20588235294117646],\n",
       " [0.25, 0.25, 0.23214285714285715]]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_fc_rate_list_3_1_snr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([8.21800631, 4.8099604 , 3.29206349]),\n",
       " array([8.28602728, 4.91995867, 3.63937399]),\n",
       " array([8.12660429, 6.46212016, 3.6963096 ]),\n",
       " array([ 8.99519589, 11.72256196,  3.88374781]),\n",
       " array([8.18742098, 5.06517235, 2.29525209]),\n",
       " array([7.74568497, 6.21914811, 3.9255391 ]),\n",
       " array([5.56500358, 6.46864019, 4.60545009]),\n",
       " array([5.5002604 ,        nan, 5.11135614]),\n",
       " array([8.10343588, 5.6077011 ,        nan]),\n",
       " array([8.60774128, 6.38604435, 4.79551877]),\n",
       " array([6.74762131, 5.18094344, 4.32727483]),\n",
       " array([7.86671997, 4.69928281, 3.29657117]),\n",
       " array([9.16106704, 6.46012257, 4.08551604]),\n",
       " array([8.70683613, 5.29165599, 3.33158773]),\n",
       " array([7.50765776, 5.9748232 , 3.97687402]),\n",
       " array([7.72567287, 5.12566095, 3.16162066])]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnmse_list_3_1_snr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,5),ncols=4, sharey=True)\n",
    "fig.suptitle('Imputation techniques accuracy for categories')\n",
    "\n",
    "for i, vect in enumerate(fc_rate_3_1_snr1): \n",
    "    ax[0].scatter(idx_j_3_1_snr1.to_numpy(), vect, label=proba_non_missing[i])\n",
    "    ax[0].plot(idx_j_3_1_snr1.to_numpy(),np.ones_like(idx_j_3_1_snr1.to_numpy())*vect.mean())\n",
    "    ax[0].set_ylabel(\"Falsely classified rate\")\n",
    "    ax[0].set_title(\"iterative FAMD on data with SNR 1\")\n",
    "    ax[0].legend()\n",
    "\n",
    "for i, vect in enumerate(fc_rate_3_1_snr3): \n",
    "    ax[1].scatter(idx_j_3_1_snr3.to_numpy(), vect, label=proba_non_missing[i])\n",
    "    ax[1].plot(idx_j_3_1_snr3.to_numpy(),np.ones_like(idx_j_3_1_snr3.to_numpy())*vect.mean())\n",
    "    ax[1].set_ylabel(\"Falsely classified rate\")\n",
    "    ax[1].set_title(\"iterative FAMD on data with SNR 1\")\n",
    "    ax[1].legend()\n",
    "\n",
    "    \n",
    "\n",
    "#fig.savefig('images/PFC_categories.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters of the second dataset created in the paper : (3.2.1 Linear and nonlinear relationships)\n",
    "\n",
    "S = 1   \n",
    "K = [5]  #K[s] = number of times the variable s (s in {1,...,S}) is duplicated in the dataset\n",
    "\n",
    "cat = 3 #number of categorical variables\n",
    "cat_idx = [3,4,5] #index of the categorical variables\n",
    "nb_of_cat_per_var = [4,4] #number of categories for each categorical variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.1 Linear and nonlinear relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
